{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822505bb-3ac3-4597-ad0a-9e61d8fdb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import sqlite3\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5aa97c8-b863-4a0a-9801-1f8ebd185f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/orestis/MyProjects/InvestorAPI/app/database/ibd.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b613eb-d7fe-4bfb-bac7-dc4a8b1cbb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_TIMEWINDOW_DAYS = 90\n",
    "\n",
    "def get_stock_fundamental_df(symbol: str) -> pd.DataFrame:\n",
    "    query = f'''\n",
    "        SELECT \n",
    "            income_statement.total_revenue,\n",
    "            income_statement.gross_profit,\n",
    "            income_statement.operating_income,\n",
    "            income_statement.net_income,\n",
    "            income_statement.ebitda,\n",
    "            income_statement.net_interest_income,\n",
    "\n",
    "            balance_sheet.total_assets,\n",
    "            balance_sheet.total_liabilities,\n",
    "            balance_sheet.total_shareholder_equity,\n",
    "            balance_sheet.total_current_assets,\n",
    "            balance_sheet.total_current_liabilities,\n",
    "            balance_sheet.cash_and_cash_equivalents_at_carrying_value,\n",
    "            balance_sheet.long_term_debt,\n",
    "            balance_sheet.current_net_receivables,\n",
    "            balance_sheet.inventory,\n",
    "            balance_sheet.property_plant_equipment,\n",
    "            \n",
    "            cash_flow.operating_cashflow,\n",
    "            cash_flow.capital_expenditures,\n",
    "            cash_flow.cashflow_from_investment,\n",
    "            cash_flow.cashflow_from_financing,\n",
    "            cash_flow.dividend_payout,\n",
    "            cash_flow.proceeds_from_issuance_of_long_term_debt_and_capital_securities_net,\n",
    "            cash_flow.payments_for_repurchase_of_equity,\n",
    "            \n",
    "            stock_overview.sector,\n",
    "            stock_overview.symbol,\n",
    "            income_statement.fiscal_date_ending\n",
    "        FROM income_statement\n",
    "        INNER JOIN balance_sheet\n",
    "            ON income_statement.fiscal_date_ending = balance_sheet.fiscal_date_ending  AND balance_sheet.symbol = '{symbol}'\n",
    "        INNER JOIN cash_flow\n",
    "            ON income_statement.fiscal_date_ending = cash_flow.fiscal_date_ending  AND cash_flow.symbol = '{symbol}'\n",
    "        INNER JOIN stock_overview\n",
    "            ON income_statement.symbol = stock_overview.symbol  AND stock_overview.symbol = '{symbol}'\n",
    "        WHERE income_statement.symbol = '{symbol}'\n",
    "        ORDER BY DATE(income_statement.fiscal_date_ending)\n",
    "    '''\n",
    "    stock_df = pd.read_sql(query, conn)\n",
    "    \n",
    "    # Drop columns with duplicated names\n",
    "    stock_df = stock_df.loc[:, ~stock_df.columns.duplicated()]\n",
    "\n",
    "    # List of columns to convert to float\n",
    "    columns_to_convert = stock_df.columns.difference(\n",
    "        ['symbol', 'fiscal_date_ending', 'sector']\n",
    "    )\n",
    "\n",
    "    # Convert selected columns to float\n",
    "    stock_df[columns_to_convert] = stock_df[columns_to_convert].astype(float)\n",
    "\n",
    "    # We fill NaN values with a small value because later we perform feature\n",
    "    # engineering to calculate pct change and ratios and we can't divide witrh zero\n",
    "    stock_df[columns_to_convert] = stock_df[columns_to_convert].fillna(0.01)\n",
    "    stock_df[columns_to_convert] = stock_df[columns_to_convert].replace(0, 0.01)\n",
    "\n",
    "    # Feature engineering\n",
    "    for column in columns_to_convert:\n",
    "        # arctan percentage change\n",
    "        log_pct_change_column_name = f'{column}_arctan_pct_change'\n",
    "        stock_df[log_pct_change_column_name] = np.arctan(stock_df[column].pct_change())\n",
    "\n",
    "        # Plain percentage change\n",
    "        pct_change_column_name = f'{column}_pct_change'\n",
    "        stock_df[pct_change_column_name] = stock_df[column].pct_change()\n",
    "\n",
    "    return stock_df\n",
    "\n",
    "\n",
    "def get_interest_rate_df() -> pd.DataFrame:\n",
    "    query = '''\n",
    "    SELECT  *\n",
    "    FROM economic_indicator_time_series\n",
    "    WHERE indicator_name = 'Interest_Rate'\n",
    "    '''\n",
    "\n",
    "    interest_rate_df = pd.read_sql(query, conn)\n",
    "    return interest_rate_df\n",
    "\n",
    "\n",
    "def get_treasury_yield_df() -> pd.DataFrame:\n",
    "    query = '''\n",
    "    SELECT  *\n",
    "    FROM economic_indicator_time_series\n",
    "    WHERE indicator_name = 'Treasury_Yield'\n",
    "    '''\n",
    "\n",
    "    treasury_yield_df = pd.read_sql(query, conn)\n",
    "    return treasury_yield_df\n",
    "\n",
    "\n",
    "def get_stock_time_series_df(symbol: str) -> pd.DataFrame:\n",
    "    query = f'''\n",
    "    SELECT  *\n",
    "    FROM stock_time_series\n",
    "    WHERE symbol = '{symbol}'\n",
    "    ORDER BY registered_date_ts DESC\n",
    "    '''\n",
    "    \n",
    "    stock_time_series_df = pd.read_sql(query, conn)\n",
    "    return stock_time_series_df\n",
    "\n",
    "\n",
    "def get_sector_time_series_df(sector: str) -> pd.DataFrame:\n",
    "    query = f'''\n",
    "    SELECT AVG(sts.close_price) AS sector_price, substr(sts.registered_date, 4, 7) AS month_year\n",
    "    FROM stock_time_series as sts\n",
    "    INNER JOIN stock_overview as so\n",
    "    ON sts.symbol = so.symbol\n",
    "    WHERE so.sector = '{sector}'\n",
    "    GROUP BY month_year\n",
    "    ORDER BY sts.registered_date_ts ASC\n",
    "    '''\n",
    "\n",
    "    sector_df = pd.read_sql(query, conn)\n",
    "    sector_df['Date'] = pd.to_datetime(sector_df['month_year'], format='%m-%Y')\n",
    "    return sector_df\n",
    "\n",
    "\n",
    "def calculate_time_series_pct_change(\n",
    "    start_date: str,\n",
    "    time_series_df: pd.DataFrame,\n",
    "    target_column: str,\n",
    "    days: int = PREDICTION_TIMEWINDOW_DAYS\n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Given a start calculate what was the pct change\n",
    "    between <start_date> and <start_date> + <days> time\n",
    "    \"\"\"\n",
    "    if days < 0:\n",
    "        lower_bound = pd.Timestamp(start_date) - pd.DateOffset(days=abs(days))\n",
    "        upper_bound = pd.Timestamp(start_date) \n",
    "    else:\n",
    "        lower_bound = pd.Timestamp(start_date)\n",
    "        upper_bound = lower_bound + pd.DateOffset(days=days)\n",
    "    \n",
    "    time_series_df['registered_date_ts'] = pd.to_datetime(time_series_df['registered_date_ts'], unit='s')\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = time_series_df[\n",
    "        (time_series_df['registered_date_ts'] >= lower_bound) & \n",
    "        (time_series_df['registered_date_ts'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sort the filtered DataFrame by timestamp\n",
    "    filtered_df = filtered_df.sort_values(by='registered_date_ts')\n",
    "\n",
    "    # Calculate pct change between first and last row\n",
    "    pct_change = ((filtered_df[target_column].iloc[-1] - filtered_df[target_column].iloc[0]) / filtered_df[target_column].iloc[0])\n",
    "    return pct_change\n",
    "\n",
    "\n",
    "def calculate_sector_pct_change(\n",
    "    start_date: dt.datetime,\n",
    "    time_series_df: pd.DataFrame,\n",
    "    days: int\n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Given a start calculate what was the pct change\n",
    "    between <start_date> and <start_date> +/- <days> time\n",
    "    \"\"\"\n",
    "    if days < 0:\n",
    "        lower_bound = start_date - pd.DateOffset(days=abs(days))\n",
    "        upper_bound = start_date \n",
    "    else:\n",
    "        lower_bound = start_date\n",
    "        upper_bound = lower_bound + pd.DateOffset(days=days)\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    filtered_df = time_series_df[\n",
    "        (time_series_df['Date'] >= lower_bound) & \n",
    "        (time_series_df['Date'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sort the filtered DataFrame by timestamp\n",
    "    filtered_df = filtered_df.sort_values(by='Date')\n",
    "\n",
    "    # Calculate pct change between first and last row\n",
    "    pct_change = ((filtered_df['sector_price'].iloc[-1] - filtered_df['sector_price'].iloc[0]) / filtered_df['sector_price'].iloc[0])\n",
    "    return pct_change\n",
    "\n",
    "\n",
    "def find_time_series_most_recent_value(\n",
    "    start_date: str,\n",
    "    time_series_df: pd.DataFrame,\n",
    "    target_column: str,\n",
    "    days: int \n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Given a start_date find the most recent value\n",
    "    between <start_date> and <start_date> +/- <days> time\n",
    "    \"\"\"\n",
    "    if days < 0:\n",
    "        lower_bound = pd.Timestamp(start_date) - pd.DateOffset(days=abs(days))\n",
    "        upper_bound = pd.Timestamp(start_date) \n",
    "    else:\n",
    "        lower_bound = pd.Timestamp(start_date)\n",
    "        upper_bound = lower_bound + pd.DateOffset(days=days)\n",
    "    \n",
    "    time_series_df['registered_date_ts'] = pd.to_datetime(time_series_df['registered_date_ts'], unit='s')\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = time_series_df[\n",
    "        (time_series_df['registered_date_ts'] >= lower_bound) & \n",
    "        (time_series_df['registered_date_ts'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sort the filtered DataFrame by timestamp\n",
    "    filtered_df = filtered_df.sort_values(by='registered_date_ts')\n",
    "    return filtered_df[target_column].iloc[-1]\n",
    "\n",
    "\n",
    "def calculate_time_series_volatility(\n",
    "    start_date: str,\n",
    "    time_series_df: pd.DataFrame,\n",
    "    target_column: str,\n",
    "    days: int = PREDICTION_TIMEWINDOW_DAYS\n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Given a start calculate what was the volatility\n",
    "    between <start_date> and <start_date> +/- <days> time\n",
    "    \"\"\"\n",
    "    if days < 0:\n",
    "        lower_bound = pd.Timestamp(start_date) - pd.DateOffset(days=abs(days))\n",
    "        upper_bound = pd.Timestamp(start_date) \n",
    "    else:\n",
    "        lower_bound = pd.Timestamp(start_date)\n",
    "        upper_bound = lower_bound + pd.DateOffset(days=days)\n",
    "    \n",
    "    time_series_df['registered_date_ts'] = pd.to_datetime(time_series_df['registered_date_ts'], unit='s')\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = time_series_df[\n",
    "        (time_series_df['registered_date_ts'] >= lower_bound) & \n",
    "        (time_series_df['registered_date_ts'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sort the filtered DataFrame by timestamp\n",
    "    filtered_df = filtered_df.sort_values(by='registered_date_ts')\n",
    "\n",
    "    volatility = filtered_df[target_column].pct_change().std()\n",
    "    return volatility\n",
    "\n",
    "\n",
    "def find_latest_financials_data(\n",
    "    start_date,\n",
    "    financials_time_series_df: pd.DataFrame,\n",
    "    days: int = 30 * 6\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the most recent financials data of a stock from 'start_date'(Going backwards)\n",
    "    \"\"\"\n",
    "    upper_bound = start_date\n",
    "    lower_bound = start_date - pd.DateOffset(days=days)\n",
    "    \n",
    "    financials_time_series_df['fiscal_date_ending'] = pd.to_datetime(financials_time_series_df['fiscal_date_ending'], format='%Y-%m-%d')\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = financials_time_series_df[\n",
    "        (financials_time_series_df['fiscal_date_ending'] >= lower_bound) & \n",
    "        (financials_time_series_df['fiscal_date_ending'] <= upper_bound)\n",
    "    ]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sort the filtered DataFrame by timestamp\n",
    "    filtered_df = filtered_df.sort_values(by='fiscal_date_ending')\n",
    "\n",
    "    columns_to_return = [col_name for col_name in filtered_df.columns if str(col_name).endswith('_arctan_pct_change')]    \n",
    "    return filtered_df[columns_to_return].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e74b11f-cac6-4c5b-992d-1be0fad99c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_rate_df = get_interest_rate_df()\n",
    "treasury_yield_df = get_treasury_yield_df()\n",
    "\n",
    "sectors_time_series = {\n",
    "    'LIFE SCIENCES': get_sector_time_series_df('LIFE SCIENCES'),\n",
    "    'TECHNOLOGY': get_sector_time_series_df('TECHNOLOGY'),\n",
    "    'TRADE & SERVICES': get_sector_time_series_df('TRADE & SERVICES'),\n",
    "    'FINANCE': get_sector_time_series_df('FINANCE'),\n",
    "    'REAL ESTATE & CONSTRUCTION': get_sector_time_series_df('REAL ESTATE & CONSTRUCTION'),\n",
    "    'MANUFACTURING': get_sector_time_series_df('MANUFACTURING'),\n",
    "    'ENERGY & TRANSPORTATION': get_sector_time_series_df('ENERGY & TRANSPORTATION')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ccfff3d-e136-4684-8ef2-44aca78126d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_prediction_data_df(symbol: str) -> pd.DataFrame:\n",
    "    stock_fundamental_df = get_stock_fundamental_df(symbol)\n",
    "    stock_time_series_df = get_stock_time_series_df(symbol)\n",
    "\n",
    "    stock_sector = stock_fundamental_df.iloc[0, stock_fundamental_df.columns.get_loc('sector')]\n",
    "    sector_time_series_df = sectors_time_series.get(stock_sector)\n",
    "\n",
    "    # Create stock prediction data\n",
    "    current_date = dt.datetime.today()\n",
    "    stock_prediction_data_df = pd.DataFrame([\n",
    "        {\"Date\": current_date},\n",
    "    ])\n",
    "    stock_prediction_data_df['symbol'] = symbol\n",
    "    stock_prediction_data_df['sector'] = stock_sector\n",
    "\n",
    "    stock_prediction_data_df['interest_rate'] = stock_prediction_data_df['Date'].apply(\n",
    "        find_time_series_most_recent_value,\n",
    "        target_column='value',\n",
    "        time_series_df=interest_rate_df,\n",
    "        days=-90\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['treasury_yield'] = stock_prediction_data_df['Date'].apply(\n",
    "        find_time_series_most_recent_value,\n",
    "        target_column='value',\n",
    "        time_series_df=treasury_yield_df,\n",
    "        days=-90\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_pct_change_last_six_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_pct_change,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-180\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_pct_change_last_three_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_pct_change,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-90\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_pct_change_last_month'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_pct_change,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-33\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_volatility_last_six_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_volatility,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-180\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_volatility_last_three_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_volatility,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-90\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['price_volatility_last_month'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_time_series_volatility,\n",
    "        target_column='close_price',\n",
    "        time_series_df=stock_time_series_df,\n",
    "        days=-33\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['sector_pct_change_last_six_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_sector_pct_change,\n",
    "        time_series_df=sector_time_series_df,\n",
    "        days=-180\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['sector_pct_change_last_three_months'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_sector_pct_change,\n",
    "        time_series_df=sector_time_series_df,\n",
    "        days=-90\n",
    "    )\n",
    "\n",
    "    stock_prediction_data_df['sector_pct_change_last_month'] = stock_prediction_data_df['Date'].apply(\n",
    "        calculate_sector_pct_change,\n",
    "        time_series_df=sector_time_series_df,\n",
    "        days=-33\n",
    "    )\n",
    "\n",
    "    financial_statements_columns = [col_name for col_name in stock_fundamental_df.columns if str(col_name).endswith('_arctan_pct_change')]\n",
    "    stock_prediction_data_df[financial_statements_columns] = stock_prediction_data_df['Date'].apply(\n",
    "        find_latest_financials_data,\n",
    "        financials_time_series_df=stock_fundamental_df,\n",
    "    )\n",
    "\n",
    "    return stock_prediction_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a45cfcae-c70d-44b8-bedd-00ad915fae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>sector</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>treasury_yield</th>\n",
       "      <th>price_pct_change_last_six_months</th>\n",
       "      <th>price_pct_change_last_three_months</th>\n",
       "      <th>price_pct_change_last_month</th>\n",
       "      <th>price_volatility_last_six_months</th>\n",
       "      <th>price_volatility_last_three_months</th>\n",
       "      <th>...</th>\n",
       "      <th>operating_income_arctan_pct_change</th>\n",
       "      <th>payments_for_repurchase_of_equity_arctan_pct_change</th>\n",
       "      <th>proceeds_from_issuance_of_long_term_debt_and_capital_securities_net_arctan_pct_change</th>\n",
       "      <th>property_plant_equipment_arctan_pct_change</th>\n",
       "      <th>total_assets_arctan_pct_change</th>\n",
       "      <th>total_current_assets_arctan_pct_change</th>\n",
       "      <th>total_current_liabilities_arctan_pct_change</th>\n",
       "      <th>total_liabilities_arctan_pct_change</th>\n",
       "      <th>total_revenue_arctan_pct_change</th>\n",
       "      <th>total_shareholder_equity_arctan_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-27 16:22:43.642917</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>5.33</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.099371</td>\n",
       "      <td>0.174125</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>0.025835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108462</td>\n",
       "      <td>-0.151872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071614</td>\n",
       "      <td>0.081882</td>\n",
       "      <td>0.125941</td>\n",
       "      <td>0.19567</td>\n",
       "      <td>0.093615</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>0.070153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date symbol      sector  interest_rate  \\\n",
       "0 2023-12-27 16:22:43.642917   MSFT  TECHNOLOGY           5.33   \n",
       "\n",
       "   treasury_yield  price_pct_change_last_six_months  \\\n",
       "0             4.5                          0.099371   \n",
       "\n",
       "   price_pct_change_last_three_months  price_pct_change_last_month  \\\n",
       "0                            0.174125                    -0.010093   \n",
       "\n",
       "   price_volatility_last_six_months  price_volatility_last_three_months  ...  \\\n",
       "0                          0.025152                            0.025835  ...   \n",
       "\n",
       "   operating_income_arctan_pct_change  \\\n",
       "0                            0.108462   \n",
       "\n",
       "   payments_for_repurchase_of_equity_arctan_pct_change  \\\n",
       "0                                          -0.151872     \n",
       "\n",
       "   proceeds_from_issuance_of_long_term_debt_and_capital_securities_net_arctan_pct_change  \\\n",
       "0                                                0.0                                       \n",
       "\n",
       "   property_plant_equipment_arctan_pct_change  total_assets_arctan_pct_change  \\\n",
       "0                                    0.071614                        0.081882   \n",
       "\n",
       "   total_current_assets_arctan_pct_change  \\\n",
       "0                                0.125941   \n",
       "\n",
       "   total_current_liabilities_arctan_pct_change  \\\n",
       "0                                      0.19567   \n",
       "\n",
       "   total_liabilities_arctan_pct_change  total_revenue_arctan_pct_change  \\\n",
       "0                             0.093615                         0.006648   \n",
       "\n",
       "   total_shareholder_equity_arctan_pct_change  \n",
       "0                                    0.070153  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_prediction_data_df('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c882c5-4087-4392-a422-6b8df711d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50704461-bd9f-4045-9309-e54be13ea6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_three_months_model = joblib.load('/Users/orestis/MyProjects/InvestorAPI/analytics/machine_learning/price_prediction_with_fundamentals/ml_models/rf_six_months_prediction_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e468a72-9165-46c8-89db-896df8fa6f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55, 0.45]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft_prediction_input = get_stock_prediction_data_df('AAPL')\n",
    "cols_to_drop = ['symbol', 'Date']\n",
    "rf_three_months_model.predict_proba(msft_prediction_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408a538-1de4-4328-8785-908e520f7c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
